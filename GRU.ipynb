{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 ∙ 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "# tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기 ∙ 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df): #데이터프레임 필터링\n",
    "    # 첫 번째 열에서 같은 값을 가진 행의 수를 계산합니다.\n",
    "    row_counts = df['0'].value_counts()\n",
    "\n",
    "    # 가장 많은 행의 수를 찾습니다.\n",
    "    max_row_count = row_counts.max()\n",
    "\n",
    "    # 가장 많은 행의 수에 해당하는 행만 분류합니다.\n",
    "    filtered = pd.DataFrame(df[df['0'].isin(row_counts[row_counts == max_row_count].index)])\n",
    "\n",
    "    return filtered\n",
    "\n",
    "# 데이터 로드   \n",
    "stock_df = pd.read_csv('/Users/moon/Desktop/Moon SeungHoo/Stock_Machine_Learning/StockData_3%.csv',low_memory=False)\n",
    "\n",
    "#데이터 필터링\n",
    "filter_stock = filter_df(stock_df)\n",
    "filter_label = filter_stock['25']\n",
    "\n",
    "# 불필요한 데이터 삭제\n",
    "filter_stock = filter_stock.drop({'0','1','7','25'},axis=1) #날자, 상승율, 5%이상 상승여부 삭제 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of zeros (0s): 0.97\n",
      "Ratio of ones (1s): 0.03\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "stock_label = scaler.fit_transform(filter_label.values.reshape(-1, 1))\n",
    "\n",
    "count_zeros = np.sum(stock_label == 0)\n",
    "count_ones = np.sum(stock_label == 1)\n",
    "total_samples = len(stock_label)\n",
    "\n",
    "ratio_zeros = (count_zeros / total_samples).round(2)\n",
    "ratio_ones = (count_ones / total_samples).round(2)\n",
    "\n",
    "print(\"Ratio of zeros (0s):\", ratio_zeros)\n",
    "print(\"Ratio of ones (1s):\", ratio_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of zeros (0s): 0.5\n",
      "Ratio of ones (1s): 0.5\n"
     ]
    }
   ],
   "source": [
    "# 훈련 및 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(filter_stock, stock_label, test_size=0.2, random_state=42)\n",
    "\n",
    "under_sampler = RandomUnderSampler(sampling_strategy='auto' , random_state=42)\n",
    "X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)\n",
    "X_test_resampled, y_test_resampled = under_sampler.fit_resample(X_test, y_test)\n",
    "\n",
    "# smote = SMOTE(sampling_strategy=0.7 ,random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train,y_train)\n",
    "# X_test_resampled, y_test_resampled = smote.fit_resample(X_test,y_test)\n",
    "\n",
    "count_zeros = np.sum(y_resampled == 0)\n",
    "count_ones = np.sum(y_resampled == 1)\n",
    "total_samples = len(y_resampled)\n",
    "\n",
    "ratio_zeros = (count_zeros / total_samples).round(2)\n",
    "ratio_ones = (count_ones / total_samples).round(2)\n",
    "\n",
    "print(\"Ratio of zeros (0s):\", ratio_zeros)\n",
    "print(\"Ratio of ones (1s):\", ratio_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 27, 64)            12864     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 27, 64)            24960     \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 187649 (733.00 KB)\n",
      "Trainable params: 187649 (733.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU 모델 정의\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.GRU(64, input_shape=(X_resampled.shape[1],1),kernel_initializer='glorot_uniform', recurrent_dropout=0.0 ,return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(64, return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 조기 종료 콜백 정의\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=30, restore_best_weights=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1713/1713 [==============================] - 227s 130ms/step - loss: 0.4284 - accuracy: 0.8119 - val_loss: 0.3505 - val_accuracy: 0.8475\n",
      "Epoch 2/500\n",
      "1713/1713 [==============================] - 224s 131ms/step - loss: 0.3432 - accuracy: 0.8554 - val_loss: 0.3545 - val_accuracy: 0.8485\n",
      "Epoch 3/500\n",
      "1713/1713 [==============================] - 223s 130ms/step - loss: 0.3217 - accuracy: 0.8647 - val_loss: 0.3176 - val_accuracy: 0.8769\n",
      "Epoch 4/500\n",
      "1713/1713 [==============================] - 222s 130ms/step - loss: 0.3101 - accuracy: 0.8697 - val_loss: 0.2733 - val_accuracy: 0.8887\n",
      "Epoch 5/500\n",
      "1713/1713 [==============================] - 236s 138ms/step - loss: 0.3037 - accuracy: 0.8719 - val_loss: 0.3018 - val_accuracy: 0.8849\n",
      "Epoch 6/500\n",
      "1713/1713 [==============================] - 227s 132ms/step - loss: 0.2955 - accuracy: 0.8767 - val_loss: 0.2695 - val_accuracy: 0.8878\n",
      "Epoch 7/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2916 - accuracy: 0.8781 - val_loss: 0.2917 - val_accuracy: 0.8802\n",
      "Epoch 8/500\n",
      "1713/1713 [==============================] - 225s 131ms/step - loss: 0.2919 - accuracy: 0.8780 - val_loss: 0.2614 - val_accuracy: 0.8939\n",
      "Epoch 9/500\n",
      "1713/1713 [==============================] - 231s 135ms/step - loss: 0.2893 - accuracy: 0.8791 - val_loss: 0.2636 - val_accuracy: 0.8920\n",
      "Epoch 10/500\n",
      "1713/1713 [==============================] - 234s 137ms/step - loss: 0.2890 - accuracy: 0.8799 - val_loss: 0.3163 - val_accuracy: 0.8680\n",
      "Epoch 11/500\n",
      "1713/1713 [==============================] - 224s 131ms/step - loss: 0.2854 - accuracy: 0.8815 - val_loss: 0.2636 - val_accuracy: 0.8919\n",
      "Epoch 12/500\n",
      "1713/1713 [==============================] - 237s 139ms/step - loss: 0.2847 - accuracy: 0.8799 - val_loss: 0.2703 - val_accuracy: 0.8885\n",
      "Epoch 13/500\n",
      "1713/1713 [==============================] - 232s 135ms/step - loss: 0.2815 - accuracy: 0.8820 - val_loss: 0.2745 - val_accuracy: 0.8881\n",
      "Epoch 14/500\n",
      "1713/1713 [==============================] - 234s 137ms/step - loss: 0.2807 - accuracy: 0.8823 - val_loss: 0.2692 - val_accuracy: 0.8879\n",
      "Epoch 15/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2804 - accuracy: 0.8819 - val_loss: 0.2898 - val_accuracy: 0.8828\n",
      "Epoch 16/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2779 - accuracy: 0.8834 - val_loss: 0.2596 - val_accuracy: 0.8945\n",
      "Epoch 17/500\n",
      "1713/1713 [==============================] - 230s 134ms/step - loss: 0.2783 - accuracy: 0.8839 - val_loss: 0.2593 - val_accuracy: 0.8929\n",
      "Epoch 18/500\n",
      "1713/1713 [==============================] - 246s 144ms/step - loss: 0.2779 - accuracy: 0.8826 - val_loss: 0.2681 - val_accuracy: 0.8887\n",
      "Epoch 19/500\n",
      "1713/1713 [==============================] - 254s 149ms/step - loss: 0.2765 - accuracy: 0.8836 - val_loss: 0.2676 - val_accuracy: 0.8916\n",
      "Epoch 20/500\n",
      "1713/1713 [==============================] - 232s 136ms/step - loss: 0.2767 - accuracy: 0.8851 - val_loss: 0.2636 - val_accuracy: 0.8940\n",
      "Epoch 21/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2757 - accuracy: 0.8848 - val_loss: 0.2857 - val_accuracy: 0.8782\n",
      "Epoch 22/500\n",
      "1713/1713 [==============================] - 237s 138ms/step - loss: 0.2717 - accuracy: 0.8863 - val_loss: 0.2810 - val_accuracy: 0.8815\n",
      "Epoch 23/500\n",
      "1713/1713 [==============================] - 242s 141ms/step - loss: 0.2718 - accuracy: 0.8864 - val_loss: 0.2539 - val_accuracy: 0.8966\n",
      "Epoch 24/500\n",
      "1713/1713 [==============================] - 224s 131ms/step - loss: 0.2684 - accuracy: 0.8880 - val_loss: 0.2683 - val_accuracy: 0.8869\n",
      "Epoch 25/500\n",
      "1713/1713 [==============================] - 225s 131ms/step - loss: 0.2711 - accuracy: 0.8866 - val_loss: 0.2786 - val_accuracy: 0.8830\n",
      "Epoch 26/500\n",
      "1713/1713 [==============================] - 231s 135ms/step - loss: 0.2690 - accuracy: 0.8877 - val_loss: 0.2726 - val_accuracy: 0.8856\n",
      "Epoch 27/500\n",
      "1713/1713 [==============================] - 227s 133ms/step - loss: 0.2679 - accuracy: 0.8869 - val_loss: 0.2649 - val_accuracy: 0.8910\n",
      "Epoch 28/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2670 - accuracy: 0.8873 - val_loss: 0.2576 - val_accuracy: 0.8942\n",
      "Epoch 29/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2656 - accuracy: 0.8887 - val_loss: 0.2873 - val_accuracy: 0.8795\n",
      "Epoch 30/500\n",
      "1713/1713 [==============================] - 235s 137ms/step - loss: 0.2622 - accuracy: 0.8894 - val_loss: 0.2825 - val_accuracy: 0.8791\n",
      "Epoch 31/500\n",
      "1713/1713 [==============================] - 230s 134ms/step - loss: 0.2649 - accuracy: 0.8882 - val_loss: 0.2765 - val_accuracy: 0.8835\n",
      "Epoch 32/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2603 - accuracy: 0.8903 - val_loss: 0.2746 - val_accuracy: 0.8815\n",
      "Epoch 33/500\n",
      "1713/1713 [==============================] - 242s 141ms/step - loss: 0.2591 - accuracy: 0.8904 - val_loss: 0.2676 - val_accuracy: 0.8895\n",
      "Epoch 34/500\n",
      "1713/1713 [==============================] - 230s 134ms/step - loss: 0.2577 - accuracy: 0.8914 - val_loss: 0.2585 - val_accuracy: 0.8932\n",
      "Epoch 35/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2562 - accuracy: 0.8912 - val_loss: 0.2608 - val_accuracy: 0.8916\n",
      "Epoch 36/500\n",
      "1713/1713 [==============================] - 249s 145ms/step - loss: 0.2547 - accuracy: 0.8915 - val_loss: 0.2781 - val_accuracy: 0.8811\n",
      "Epoch 37/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2549 - accuracy: 0.8920 - val_loss: 0.2637 - val_accuracy: 0.8887\n",
      "Epoch 38/500\n",
      "1713/1713 [==============================] - 247s 144ms/step - loss: 0.2524 - accuracy: 0.8938 - val_loss: 0.2641 - val_accuracy: 0.8922\n",
      "Epoch 39/500\n",
      "1713/1713 [==============================] - 227s 133ms/step - loss: 0.2538 - accuracy: 0.8938 - val_loss: 0.2633 - val_accuracy: 0.8918\n",
      "Epoch 40/500\n",
      "1713/1713 [==============================] - 255s 149ms/step - loss: 0.2519 - accuracy: 0.8935 - val_loss: 0.2679 - val_accuracy: 0.8902\n",
      "Epoch 41/500\n",
      "1713/1713 [==============================] - 231s 135ms/step - loss: 0.2501 - accuracy: 0.8937 - val_loss: 0.2663 - val_accuracy: 0.8896\n",
      "Epoch 42/500\n",
      "1713/1713 [==============================] - 230s 134ms/step - loss: 0.2500 - accuracy: 0.8935 - val_loss: 0.2703 - val_accuracy: 0.8885\n",
      "Epoch 43/500\n",
      "1713/1713 [==============================] - 256s 149ms/step - loss: 0.2523 - accuracy: 0.8936 - val_loss: 0.2623 - val_accuracy: 0.8924\n",
      "Epoch 44/500\n",
      "1713/1713 [==============================] - 230s 134ms/step - loss: 0.2513 - accuracy: 0.8943 - val_loss: 0.2916 - val_accuracy: 0.8764\n",
      "Epoch 45/500\n",
      "1713/1713 [==============================] - 240s 140ms/step - loss: 0.2505 - accuracy: 0.8950 - val_loss: 0.2758 - val_accuracy: 0.8875\n",
      "Epoch 46/500\n",
      "1713/1713 [==============================] - 245s 143ms/step - loss: 0.2481 - accuracy: 0.8950 - val_loss: 0.2617 - val_accuracy: 0.8929\n",
      "Epoch 47/500\n",
      "1713/1713 [==============================] - 236s 138ms/step - loss: 0.2471 - accuracy: 0.8946 - val_loss: 0.2821 - val_accuracy: 0.8829\n",
      "Epoch 48/500\n",
      "1713/1713 [==============================] - 239s 140ms/step - loss: 0.2451 - accuracy: 0.8966 - val_loss: 0.2639 - val_accuracy: 0.8920\n",
      "Epoch 49/500\n",
      "1713/1713 [==============================] - 266s 155ms/step - loss: 0.2454 - accuracy: 0.8963 - val_loss: 0.2725 - val_accuracy: 0.8872\n",
      "Epoch 50/500\n",
      "1713/1713 [==============================] - 235s 137ms/step - loss: 0.2455 - accuracy: 0.8957 - val_loss: 0.2843 - val_accuracy: 0.8807\n",
      "Epoch 51/500\n",
      "1713/1713 [==============================] - 235s 137ms/step - loss: 0.2462 - accuracy: 0.8961 - val_loss: 0.2901 - val_accuracy: 0.8828\n",
      "Epoch 52/500\n",
      "1713/1713 [==============================] - 233s 136ms/step - loss: 0.2423 - accuracy: 0.8963 - val_loss: 0.2903 - val_accuracy: 0.8829\n",
      "Epoch 53/500\n",
      "1713/1713 [==============================] - 238s 139ms/step - loss: 0.2397 - accuracy: 0.8984 - val_loss: 0.2813 - val_accuracy: 0.8825\n",
      "Epoch 54/500\n",
      "1713/1713 [==============================] - 255s 149ms/step - loss: 0.2407 - accuracy: 0.8984 - val_loss: 0.2687 - val_accuracy: 0.8893\n",
      "Epoch 55/500\n",
      "1713/1713 [==============================] - 245s 143ms/step - loss: 0.2388 - accuracy: 0.8995 - val_loss: 0.2705 - val_accuracy: 0.8891\n",
      "Epoch 56/500\n",
      "1713/1713 [==============================] - 246s 144ms/step - loss: 0.2404 - accuracy: 0.8999 - val_loss: 0.2823 - val_accuracy: 0.8874\n",
      "Epoch 57/500\n",
      "1713/1713 [==============================] - 246s 144ms/step - loss: 0.2408 - accuracy: 0.8984 - val_loss: 0.2820 - val_accuracy: 0.8845\n",
      "Epoch 58/500\n",
      "1713/1713 [==============================] - 238s 139ms/step - loss: 0.2387 - accuracy: 0.9001 - val_loss: 0.2813 - val_accuracy: 0.8837\n",
      "Epoch 59/500\n",
      "1713/1713 [==============================] - 238s 139ms/step - loss: 0.2337 - accuracy: 0.9011 - val_loss: 0.2797 - val_accuracy: 0.8883\n",
      "Epoch 60/500\n",
      "1713/1713 [==============================] - 242s 141ms/step - loss: 0.2345 - accuracy: 0.9003 - val_loss: 0.2849 - val_accuracy: 0.8842\n",
      "Epoch 61/500\n",
      "1713/1713 [==============================] - 233s 136ms/step - loss: 0.2327 - accuracy: 0.9001 - val_loss: 0.2737 - val_accuracy: 0.8908\n",
      "Epoch 62/500\n",
      "1713/1713 [==============================] - 227s 133ms/step - loss: 0.2299 - accuracy: 0.9028 - val_loss: 0.2780 - val_accuracy: 0.8888\n",
      "Epoch 63/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2308 - accuracy: 0.9024 - val_loss: 0.2869 - val_accuracy: 0.8848\n",
      "Epoch 64/500\n",
      "1713/1713 [==============================] - 224s 131ms/step - loss: 0.2318 - accuracy: 0.9021 - val_loss: 0.2884 - val_accuracy: 0.8819\n",
      "Epoch 65/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2312 - accuracy: 0.9026 - val_loss: 0.2828 - val_accuracy: 0.8870\n",
      "Epoch 66/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2288 - accuracy: 0.9028 - val_loss: 0.2999 - val_accuracy: 0.8809\n",
      "Epoch 67/500\n",
      "1713/1713 [==============================] - 233s 136ms/step - loss: 0.2280 - accuracy: 0.9035 - val_loss: 0.2837 - val_accuracy: 0.8848\n",
      "Epoch 68/500\n",
      "1713/1713 [==============================] - 232s 135ms/step - loss: 0.2261 - accuracy: 0.9053 - val_loss: 0.2811 - val_accuracy: 0.8872\n",
      "Epoch 69/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2268 - accuracy: 0.9046 - val_loss: 0.2929 - val_accuracy: 0.8838\n",
      "Epoch 70/500\n",
      "1713/1713 [==============================] - 224s 131ms/step - loss: 0.2257 - accuracy: 0.9034 - val_loss: 0.2901 - val_accuracy: 0.8858\n",
      "Epoch 71/500\n",
      "1713/1713 [==============================] - 225s 132ms/step - loss: 0.2249 - accuracy: 0.9040 - val_loss: 0.3209 - val_accuracy: 0.8746\n",
      "Epoch 72/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2249 - accuracy: 0.9037 - val_loss: 0.2826 - val_accuracy: 0.8870\n",
      "Epoch 73/500\n",
      "1713/1713 [==============================] - 226s 132ms/step - loss: 0.2248 - accuracy: 0.9038 - val_loss: 0.2935 - val_accuracy: 0.8825\n",
      "Epoch 74/500\n",
      "1713/1713 [==============================] - 236s 138ms/step - loss: 0.2231 - accuracy: 0.9048 - val_loss: 0.2814 - val_accuracy: 0.8871\n",
      "Epoch 75/500\n",
      "1713/1713 [==============================] - 241s 141ms/step - loss: 0.2226 - accuracy: 0.9052 - val_loss: 0.3126 - val_accuracy: 0.8797\n",
      "Epoch 76/500\n",
      "1713/1713 [==============================] - 247s 144ms/step - loss: 0.2195 - accuracy: 0.9059 - val_loss: 0.3098 - val_accuracy: 0.8797\n",
      "Epoch 77/500\n",
      "1713/1713 [==============================] - 235s 137ms/step - loss: 0.2172 - accuracy: 0.9077 - val_loss: 0.2924 - val_accuracy: 0.8868\n",
      "Epoch 78/500\n",
      "1713/1713 [==============================] - 253s 148ms/step - loss: 0.2211 - accuracy: 0.9056 - val_loss: 0.2860 - val_accuracy: 0.8846\n",
      "Epoch 79/500\n",
      "1713/1713 [==============================] - 227s 132ms/step - loss: 0.2254 - accuracy: 0.9042 - val_loss: 0.2952 - val_accuracy: 0.8815\n",
      "Epoch 80/500\n",
      "1713/1713 [==============================] - 227s 133ms/step - loss: 0.2192 - accuracy: 0.9065 - val_loss: 0.2923 - val_accuracy: 0.8847\n",
      "Epoch 81/500\n",
      "1713/1713 [==============================] - 251s 147ms/step - loss: 0.2206 - accuracy: 0.9074 - val_loss: 0.2898 - val_accuracy: 0.8847\n",
      "Epoch 82/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2200 - accuracy: 0.9070 - val_loss: 0.3023 - val_accuracy: 0.8826\n",
      "Epoch 83/500\n",
      "1713/1713 [==============================] - 228s 133ms/step - loss: 0.2197 - accuracy: 0.9074 - val_loss: 0.3089 - val_accuracy: 0.8815\n",
      "Epoch 84/500\n",
      "1713/1713 [==============================] - 229s 134ms/step - loss: 0.2151 - accuracy: 0.9082 - val_loss: 0.3150 - val_accuracy: 0.8760\n",
      "Epoch 85/500\n",
      "1713/1713 [==============================] - 231s 135ms/step - loss: 0.2138 - accuracy: 0.9085 - val_loss: 0.3378 - val_accuracy: 0.8737\n",
      "Epoch 86/500\n",
      "1713/1713 [==============================] - 252s 147ms/step - loss: 0.2146 - accuracy: 0.9090 - val_loss: 0.3002 - val_accuracy: 0.8875\n",
      "Epoch 87/500\n",
      "1713/1713 [==============================] - 250s 146ms/step - loss: 0.2121 - accuracy: 0.9094 - val_loss: 0.3022 - val_accuracy: 0.8803\n",
      "Epoch 88/500\n",
      "1713/1713 [==============================] - 235s 137ms/step - loss: 0.2123 - accuracy: 0.9096 - val_loss: 0.3080 - val_accuracy: 0.8802\n",
      "Epoch 89/500\n",
      "1713/1713 [==============================] - 237s 138ms/step - loss: 0.2124 - accuracy: 0.9097 - val_loss: 0.2964 - val_accuracy: 0.8840\n",
      "Epoch 90/500\n",
      "1713/1713 [==============================] - 236s 138ms/step - loss: 0.2102 - accuracy: 0.9110 - val_loss: 0.3025 - val_accuracy: 0.8852\n",
      "Epoch 91/500\n",
      "1713/1713 [==============================] - 247s 144ms/step - loss: 0.2158 - accuracy: 0.9098 - val_loss: 0.3039 - val_accuracy: 0.8807\n",
      "Epoch 92/500\n",
      "1713/1713 [==============================] - 231s 135ms/step - loss: 0.2103 - accuracy: 0.9108 - val_loss: 0.3188 - val_accuracy: 0.8744\n",
      "Epoch 93/500\n",
      "1713/1713 [==============================] - 238s 139ms/step - loss: 0.2073 - accuracy: 0.9117 - val_loss: 0.3241 - val_accuracy: 0.8800\n",
      "Epoch 94/500\n",
      "1713/1713 [==============================] - 244s 143ms/step - loss: 0.2087 - accuracy: 0.9112 - val_loss: 0.3216 - val_accuracy: 0.8798\n",
      "Epoch 95/500\n",
      "1713/1713 [==============================] - 241s 141ms/step - loss: 0.2054 - accuracy: 0.9119 - val_loss: 0.3104 - val_accuracy: 0.8838\n",
      "Epoch 96/500\n",
      "1713/1713 [==============================] - 237s 139ms/step - loss: 0.2049 - accuracy: 0.9131 - val_loss: 0.2976 - val_accuracy: 0.8844\n",
      "Epoch 97/500\n",
      "1713/1713 [==============================] - 241s 141ms/step - loss: 0.2085 - accuracy: 0.9108 - val_loss: 0.2984 - val_accuracy: 0.8861\n",
      "Epoch 98/500\n",
      "1713/1713 [==============================] - 238s 139ms/step - loss: 0.2090 - accuracy: 0.9098 - val_loss: 0.3052 - val_accuracy: 0.8827\n",
      "Epoch 99/500\n",
      "1713/1713 [==============================] - 227s 133ms/step - loss: 0.2046 - accuracy: 0.9134 - val_loss: 0.3203 - val_accuracy: 0.8823\n",
      "Epoch 100/500\n",
      "1713/1713 [==============================] - 221s 129ms/step - loss: 0.2060 - accuracy: 0.9124 - val_loss: 0.3210 - val_accuracy: 0.8817\n",
      "Epoch 101/500\n",
      "1713/1713 [==============================] - 218s 127ms/step - loss: 0.2076 - accuracy: 0.9121 - val_loss: 0.3326 - val_accuracy: 0.8736\n",
      "Epoch 102/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2080 - accuracy: 0.9112 - val_loss: 0.3222 - val_accuracy: 0.8801\n",
      "Epoch 103/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2025 - accuracy: 0.9137 - val_loss: 0.3115 - val_accuracy: 0.8827\n",
      "Epoch 104/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2096 - accuracy: 0.9110 - val_loss: 0.3084 - val_accuracy: 0.8841\n",
      "Epoch 105/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2084 - accuracy: 0.9122 - val_loss: 0.3041 - val_accuracy: 0.8829\n",
      "Epoch 106/500\n",
      "1713/1713 [==============================] - 215s 126ms/step - loss: 0.2095 - accuracy: 0.9111 - val_loss: 0.2964 - val_accuracy: 0.8835\n",
      "Epoch 107/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2074 - accuracy: 0.9122 - val_loss: 0.3118 - val_accuracy: 0.8796\n",
      "Epoch 108/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2067 - accuracy: 0.9119 - val_loss: 0.3136 - val_accuracy: 0.8807\n",
      "Epoch 109/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2078 - accuracy: 0.9128 - val_loss: 0.3195 - val_accuracy: 0.8763\n",
      "Epoch 110/500\n",
      "1713/1713 [==============================] - 215s 125ms/step - loss: 0.2032 - accuracy: 0.9141 - val_loss: 0.3097 - val_accuracy: 0.8810\n",
      "Epoch 111/500\n",
      "1713/1713 [==============================] - 222s 129ms/step - loss: 0.2050 - accuracy: 0.9122 - val_loss: 0.3151 - val_accuracy: 0.8788\n",
      "Epoch 112/500\n",
      "1713/1713 [==============================] - 221s 129ms/step - loss: 0.2037 - accuracy: 0.9133 - val_loss: 0.3219 - val_accuracy: 0.8780\n",
      "Epoch 113/500\n",
      "1713/1713 [==============================] - 213s 125ms/step - loss: 0.2056 - accuracy: 0.9135 - val_loss: 0.3014 - val_accuracy: 0.8856\n",
      "Epoch 114/500\n",
      "1713/1713 [==============================] - 215s 125ms/step - loss: 0.2027 - accuracy: 0.9128 - val_loss: 0.3253 - val_accuracy: 0.8779\n",
      "Epoch 115/500\n",
      "1713/1713 [==============================] - 220s 129ms/step - loss: 0.2085 - accuracy: 0.9112 - val_loss: 0.3218 - val_accuracy: 0.8748\n",
      "Epoch 116/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2061 - accuracy: 0.9130 - val_loss: 0.3153 - val_accuracy: 0.8803\n",
      "Epoch 117/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2056 - accuracy: 0.9135 - val_loss: 0.3170 - val_accuracy: 0.8774\n",
      "Epoch 118/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2023 - accuracy: 0.9140 - val_loss: 0.3537 - val_accuracy: 0.8739\n",
      "Epoch 119/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2110 - accuracy: 0.9108 - val_loss: 0.3078 - val_accuracy: 0.8807\n",
      "Epoch 120/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2014 - accuracy: 0.9144 - val_loss: 0.3516 - val_accuracy: 0.8692\n",
      "Epoch 121/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2026 - accuracy: 0.9144 - val_loss: 0.3240 - val_accuracy: 0.8800\n",
      "Epoch 122/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2048 - accuracy: 0.9130 - val_loss: 0.3190 - val_accuracy: 0.8775\n",
      "Epoch 123/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2025 - accuracy: 0.9142 - val_loss: 0.3181 - val_accuracy: 0.8787\n",
      "Epoch 124/500\n",
      "1713/1713 [==============================] - 215s 126ms/step - loss: 0.2047 - accuracy: 0.9129 - val_loss: 0.3268 - val_accuracy: 0.8801\n",
      "Epoch 125/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2007 - accuracy: 0.9149 - val_loss: 0.3307 - val_accuracy: 0.8783\n",
      "Epoch 126/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2065 - accuracy: 0.9121 - val_loss: 0.3139 - val_accuracy: 0.8804\n",
      "Epoch 127/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2047 - accuracy: 0.9129 - val_loss: 0.3045 - val_accuracy: 0.8825\n",
      "Epoch 128/500\n",
      "1713/1713 [==============================] - 218s 128ms/step - loss: 0.2030 - accuracy: 0.9133 - val_loss: 0.3293 - val_accuracy: 0.8832\n",
      "Epoch 129/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2081 - accuracy: 0.9122 - val_loss: 0.3287 - val_accuracy: 0.8775\n",
      "Epoch 130/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2077 - accuracy: 0.9121 - val_loss: 0.3089 - val_accuracy: 0.8815\n",
      "Epoch 131/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2069 - accuracy: 0.9124 - val_loss: 0.3198 - val_accuracy: 0.8782\n",
      "Epoch 132/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2032 - accuracy: 0.9149 - val_loss: 0.3308 - val_accuracy: 0.8745\n",
      "Epoch 133/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2078 - accuracy: 0.9115 - val_loss: 0.3447 - val_accuracy: 0.8720\n",
      "Epoch 134/500\n",
      "1713/1713 [==============================] - 220s 129ms/step - loss: 0.2046 - accuracy: 0.9133 - val_loss: 0.2923 - val_accuracy: 0.8859\n",
      "Epoch 135/500\n",
      "1713/1713 [==============================] - 220s 129ms/step - loss: 0.2008 - accuracy: 0.9135 - val_loss: 0.3142 - val_accuracy: 0.8808\n",
      "Epoch 136/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2035 - accuracy: 0.9141 - val_loss: 0.3136 - val_accuracy: 0.8812\n",
      "Epoch 137/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2075 - accuracy: 0.9108 - val_loss: 0.3094 - val_accuracy: 0.8777\n",
      "Epoch 138/500\n",
      "1713/1713 [==============================] - 221s 129ms/step - loss: 0.2054 - accuracy: 0.9127 - val_loss: 0.3453 - val_accuracy: 0.8763\n",
      "Epoch 139/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2064 - accuracy: 0.9131 - val_loss: 0.3258 - val_accuracy: 0.8748\n",
      "Epoch 140/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2061 - accuracy: 0.9123 - val_loss: 0.3194 - val_accuracy: 0.8748\n",
      "Epoch 141/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2040 - accuracy: 0.9136 - val_loss: 0.3184 - val_accuracy: 0.8801\n",
      "Epoch 142/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2058 - accuracy: 0.9142 - val_loss: 0.3140 - val_accuracy: 0.8824\n",
      "Epoch 143/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.2066 - accuracy: 0.9123 - val_loss: 0.3186 - val_accuracy: 0.8800\n",
      "Epoch 144/500\n",
      "1713/1713 [==============================] - 221s 129ms/step - loss: 0.2076 - accuracy: 0.9130 - val_loss: 0.3234 - val_accuracy: 0.8767\n",
      "Epoch 145/500\n",
      "1713/1713 [==============================] - 217s 127ms/step - loss: 0.1996 - accuracy: 0.9156 - val_loss: 0.3315 - val_accuracy: 0.8782\n",
      "Epoch 146/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2248 - accuracy: 0.9050 - val_loss: 0.2975 - val_accuracy: 0.8840\n",
      "Epoch 147/500\n",
      "1713/1713 [==============================] - 212s 124ms/step - loss: 0.2139 - accuracy: 0.9091 - val_loss: 0.2979 - val_accuracy: 0.8833\n",
      "Epoch 148/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2123 - accuracy: 0.9104 - val_loss: 0.3295 - val_accuracy: 0.8748\n",
      "Epoch 149/500\n",
      "1713/1713 [==============================] - 215s 126ms/step - loss: 0.2007 - accuracy: 0.9153 - val_loss: 0.3238 - val_accuracy: 0.8777\n",
      "Epoch 150/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2056 - accuracy: 0.9126 - val_loss: 0.3214 - val_accuracy: 0.8778\n",
      "Epoch 151/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2102 - accuracy: 0.9103 - val_loss: 0.3053 - val_accuracy: 0.8828\n",
      "Epoch 152/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2042 - accuracy: 0.9139 - val_loss: 0.3176 - val_accuracy: 0.8796\n",
      "Epoch 153/500\n",
      "1713/1713 [==============================] - 219s 128ms/step - loss: 0.2079 - accuracy: 0.9113 - val_loss: 0.3402 - val_accuracy: 0.8651\n",
      "Epoch 154/500\n",
      "1713/1713 [==============================] - 215s 125ms/step - loss: 0.2070 - accuracy: 0.9125 - val_loss: 0.3145 - val_accuracy: 0.8801\n",
      "Epoch 155/500\n",
      "1713/1713 [==============================] - 218s 127ms/step - loss: 0.2081 - accuracy: 0.9118 - val_loss: 0.3156 - val_accuracy: 0.8824\n",
      "Epoch 156/500\n",
      "1713/1713 [==============================] - 220s 128ms/step - loss: 0.2033 - accuracy: 0.9141 - val_loss: 0.3194 - val_accuracy: 0.8813\n",
      "Epoch 157/500\n",
      "1713/1713 [==============================] - 215s 125ms/step - loss: 0.2048 - accuracy: 0.9135 - val_loss: 0.3177 - val_accuracy: 0.8815\n",
      "Epoch 158/500\n",
      "1713/1713 [==============================] - 215s 126ms/step - loss: 0.2088 - accuracy: 0.9122 - val_loss: 0.2995 - val_accuracy: 0.8843\n",
      "Epoch 159/500\n",
      "1713/1713 [==============================] - 220s 128ms/step - loss: 0.2080 - accuracy: 0.9108 - val_loss: 0.3106 - val_accuracy: 0.8820\n",
      "Epoch 160/500\n",
      "1713/1713 [==============================] - 220s 128ms/step - loss: 0.2088 - accuracy: 0.9111 - val_loss: 0.3253 - val_accuracy: 0.8803\n",
      "Epoch 161/500\n",
      "1713/1713 [==============================] - 214s 125ms/step - loss: 0.2041 - accuracy: 0.9128 - val_loss: 0.3110 - val_accuracy: 0.8824\n",
      "Epoch 162/500\n",
      "1713/1713 [==============================] - 222s 130ms/step - loss: 0.2079 - accuracy: 0.9113 - val_loss: 0.3056 - val_accuracy: 0.8813\n",
      "Epoch 163/500\n",
      "1713/1713 [==============================] - 215s 126ms/step - loss: 0.2041 - accuracy: 0.9144 - val_loss: 0.3094 - val_accuracy: 0.8802\n",
      "Epoch 164/500\n",
      "1713/1713 [==============================] - 220s 128ms/step - loss: 0.2112 - accuracy: 0.9115 - val_loss: 0.3108 - val_accuracy: 0.8786\n",
      "Epoch 165/500\n",
      "1713/1713 [==============================] - 216s 126ms/step - loss: 0.2126 - accuracy: 0.9100 - val_loss: 0.3119 - val_accuracy: 0.8803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moon/anaconda3/envs/ML/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(X_resampled,y_resampled,epochs=500,\n",
    "validation_data=(X_test_resampled, y_test_resampled),callbacks=[early_stopping])\n",
    " \n",
    "# 모델 저장\n",
    "model.save(\"GRU_Model_8L_64_3%.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13183/13183 [==============================] - 141s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "# loaded_model = tf.keras.models.load_model(\"GRU_Model_8L_64_10%.h5\")\n",
    "\n",
    "# 모델을 사용하여 주가 상승 여부 예측\n",
    "test = model.predict(X_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8781903734695571\n",
      "Confusion Matrix:\n",
      "[[214048  34102]\n",
      " [ 17284 156421]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.89    248150\n",
      "         1.0       0.82      0.90      0.86    173705\n",
      "\n",
      "    accuracy                           0.88    421855\n",
      "   macro avg       0.87      0.88      0.88    421855\n",
      "weighted avg       0.88      0.88      0.88    421855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary = (test > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred_binary)\n",
    "conf_matrix = confusion_matrix(y_test_resampled, y_pred_binary)\n",
    "classification_rep = classification_report(y_test_resampled, y_pred_binary)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
